{
  "model_name": "seq2seq_lstm",
  "epochs": 16,
  "checkpoint_every": 10000,
  "eval_every": 10000,
  "learning_rate": 1e-3,
  "optimization": "adam",
  "embedding_size": 200,
  "encoder_hidden_sizes": [256],
  "decoder_hidden_sizes": [256],
  "batch_size": 64,
  "keep_prob": 0.5,
  "vocab_size": 50000,
  "schedule_sample": false,
  "beam_search": true,
  "beam_size": 10,
  "use_antilm": false,
  "use_bpe": false,
  "use_attention": true,
  "max_grad_norm": 5.0,
  "train_data": "data/weibo/post_response_train.txt",
  "eval_data": "data/weibo/post_response_eval.txt",
  "output_path": "outputs/weibo/lstm",
  "word_vectors_path": null,
  "ckpt_model_path": "ckpt_model/weibo/lstm"
}

